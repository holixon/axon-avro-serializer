{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Why should I use it? # We believe that serialization of events for messaging and storage purpose is done best using Apache Avro data serialization system. For this purpose we designed and implemented an Avro Serializer for Axon Framework to foster usage of Apache Avro as a serialization format for events , instead of XML or JSON. Why? # Avro is schema based Avro Schema allows detection of incompatibilities during Schema Evolution Avro supports binary encoding which saves space Interested? # You can get more details if you start understanding Concepts . For further details, please check our reference guide . We also provide some Examples demonstrating the usage of the extension in a simple Axon Bank Scenario.","title":"Home"},{"location":"index.html#why-should-i-use-it","text":"We believe that serialization of events for messaging and storage purpose is done best using Apache Avro data serialization system. For this purpose we designed and implemented an Avro Serializer for Axon Framework to foster usage of Apache Avro as a serialization format for events , instead of XML or JSON.","title":"Why should I use it?"},{"location":"index.html#why","text":"Avro is schema based Avro Schema allows detection of incompatibilities during Schema Evolution Avro supports binary encoding which saves space","title":"Why?"},{"location":"index.html#interested","text":"You can get more details if you start understanding Concepts . For further details, please check our reference guide . We also provide some Examples demonstrating the usage of the extension in a simple Axon Bank Scenario.","title":"Interested?"},{"location":"developer-guide.html","text":"Design decisions # We decided to create a sister project Avro Registry Adapter which eases the work with Apache Avro and defines the API and implementations for Schema Registry . In doing so, we provide a maximum independence of the serialization process from the used registry. The extension itself is implemented in Kotlin only, since we need to work with JVM and Axon Framework and Kotlin is more fun. The extension is usable from Kotlin and Java, although the API might have advantages when using Kotlin. References # There are some resources on the Internet, which might be helpful to understand the design decisions and implementation. Here is a short collection of links: Notes # https://github.com/sksamuel/avro4k https://www.baeldung.com/java-apache-avro https://avro.apache.org/docs/current/gettingstartedjava.html http://bigdatums.net/2016/01/20/simple-apache-avro-example-using-java/ http://www.soutier.de/blog/2017/03/07/daten-modellieren-avro/ Great to read # https://blog.cloudera.com/robust-message-serialization-in-apache-kafka-using-apache-avro-part-1/ https://github.com/cloudera/kafka-examples","title":"Developer Guide"},{"location":"developer-guide.html#design-decisions","text":"We decided to create a sister project Avro Registry Adapter which eases the work with Apache Avro and defines the API and implementations for Schema Registry . In doing so, we provide a maximum independence of the serialization process from the used registry. The extension itself is implemented in Kotlin only, since we need to work with JVM and Axon Framework and Kotlin is more fun. The extension is usable from Kotlin and Java, although the API might have advantages when using Kotlin.","title":"Design decisions"},{"location":"developer-guide.html#references","text":"There are some resources on the Internet, which might be helpful to understand the design decisions and implementation. Here is a short collection of links:","title":"References"},{"location":"developer-guide.html#notes","text":"https://github.com/sksamuel/avro4k https://www.baeldung.com/java-apache-avro https://avro.apache.org/docs/current/gettingstartedjava.html http://bigdatums.net/2016/01/20/simple-apache-avro-example-using-java/ http://www.soutier.de/blog/2017/03/07/daten-modellieren-avro/","title":"Notes"},{"location":"developer-guide.html#great-to-read","text":"https://blog.cloudera.com/robust-message-serialization-in-apache-kafka-using-apache-avro-part-1/ https://github.com/cloudera/kafka-examples","title":"Great to read"},{"location":"getting-started.html","text":"Put the serializer library and one of the registry adapters on the class path of you project: <dependency> <groupId> io.holixon.axon.avro </groupId> <artifactId> axon-avro-serializer-spring </artifactId> <version> ${axon-avro-serializer.version} </version> </dependency> <dependency> <groupId> io.holixon.avro </groupId> <artifactId> avro-registry-adapter-apicurio </artifactId> <version> ${avro-registry.version} </version> </dependency> Activate the used registry adapter and the serializer in your configuration: @EnableAxonAvroSerializer class MyConfiguration { @Bean fun avroSchemaRegistry (): AvroSchemaRegistry { return ... } }","title":"Getting started"},{"location":"concepts/index.html","text":"Apache Avro is a data serialization system based on schemas , defined in JSON. A schema is required to write data and to read data. In particular, this means that Apache Avro is using a so-called schema-first approach. First, a schema is created and distributed, then it is used to serialize the message and used again to deserialize the message back. In general, the presence of the schema is sufficient to read and write data, but for statically-typed languages like Java or Kotlin, it is common to generate static classes using Avro Code Generator. Avro is flexible in where to get this schema from, so we defined a Schema Registry API to de-couple the user from the implementation of the schema registry. This allowed us to define multiple interchangeable implementation of the registry adapters . The following figure demonstrates this approach:","title":"Overview"},{"location":"concepts/event-generation.html","text":"In order to work with the Axon Framework, we need to have Java (or Kotlin) classes representing the events defined in the schema to be available. This class is generated from the schema using Avro generator. In order to do so, the build environment must have access to the schema (registry) and use a build system plugin (Maven or Gradle) to generate java/kt source files Please see example in the reference guide for more details. Note The class FQN will suffice to identity the published schema, but for the Axon default upcasters to work, a @Revision annotation on the class file is needed. For this purpose, a special SchemaBasedRevisionResolver is implemented and configured in the Avro serializer.","title":"Event generation"},{"location":"concepts/schema-design.html","text":"Based on the business requirements for the events of the bounded context, an Avro Schema definition is created. It describes all properties of the event and is defined using JSON. Most Important: event namespace (in which context is this event relevant? could be context's name prefixed by the domain, example: example.bankaccount.event ) event name (describing what happened in a simple past tense. Meaningful in context, example: BankAccountCreated ) event revision (when we later modify the event content, which is the revision we relate to, example: 1 ) event reference identifier (business aggregate identifier this event relates to, example: bankAccountId ) The schema can be identified by the URL of namespace.name , which will later also be the FQN of the generated classes, used for handling the event instances. Important We consider that the namespace of the business context and the name of an event should not change over time when they are modelled properly in advance. So it might be a good option not to force a typical java-package pattern on them, which would require renaming when refactorings are done. The revision should be defined as a metadata of the schema, not a property inside. Here is an example: { \"type\" : \"record\" , \"namespace\" : \"example.bankaccount.event\" , \"name\" : \"BankAccountCreatedEvent\" , \"fields\" : [ { \"name\" : \"bankAccountId\" , \"type\" : \"string\" }, { \"name\" : \"initialBalance\" , \"type\" : \"int\" } ], \"revision\" : \"1\" } For more details, please consult the Avro Specification .","title":"Schema design"},{"location":"concepts/schema-publication.html","text":"Once we are happy with our schema design , we publish it to a schema registry. This extension is not enforcing usage of a particular registry but instead provide flexible registry adapters . The registry must be available at build and runtime because we need it for code generation and runtime validation/migration.","title":"Schema publication"},{"location":"concepts/schema-registry.html","text":"Schema registry is a central concept introduced to decouple storage and management of schemas from the usage of schemas for serialization and deserialization. In order to decouple from concrete implementation, we defined an API to work with registries in the sister project Avro Registry Adapter . There are several registry adapters available, which can be used in your implementation. Currently, they are: In-Memory registry for a transient registry Apicurio Registry Adapter to connect to apicur.io Registry The following registries will be available shortly: JPA registry for storing schemas in RDBMS Confluent registry adapter to work with Confluent Schema Registry Using one of those adapters you can reuse the existing registry. Every registry adapter needs its specific configuration to operate properly. In the Registry Adapters section, the examples of configuration is provided. For more details, please consult the documentation of the Avro Registry Adapter project. Registry Performance # Since the Schema registry is required for any serialization and deserialization process, performance of the schema resolution is vital. To address this requirement, we provide a mechanism of a Composite Registry , effectively building a chain of registries. It might be a good idea to have an in-memory registry as the main registry used in the application, backed by a remote schema registry connected via selected registry adapter.","title":"Schema registry"},{"location":"concepts/schema-registry.html#registry-performance","text":"Since the Schema registry is required for any serialization and deserialization process, performance of the schema resolution is vital. To address this requirement, we provide a mechanism of a Composite Registry , effectively building a chain of registries. It might be a good idea to have an in-memory registry as the main registry used in the application, backed by a remote schema registry connected via selected registry adapter.","title":"Registry Performance"},{"location":"concepts/upcasting.html","text":"Upcasting is the process of matching the structure of the event intermediate representation of an event to the target type of the event. It is required if the structure of the event of the writer side is not matching the structure of the event of the reader side. In general, we speak about event evolution, which is described in the context of Avro with the concept of Schema Evolution. Luckily, Avro provides a foundation of detection of schema changes and allows for a classification of those changes - some of those changes are non-breaking and some are breaking. The task for the upcaster is to overcome the breaking changes. In order to upcast a Avro-serialized message, the intermediate representation is constructed. Since it is not easily possible to upcast binary data directly, we provide a converter of binary data into a Generic Record format which is essentially a Map<String, Object> structure. An upcaster may modify this map to match the target event type. In addition, it needs to change the schema information (schema namespace, name, revision) of the Generic Record to match the reader schema.","title":"Upcasting"},{"location":"reference/index.html","text":"Encoding # Apache Avro provides several encoding formats. The current extension uses Single Object Encoded format for binary data representation. Using this format, the encoded data is binary encoded and contains a special CRC-64-AVRO fingerprint of the object's schema. The extension is using this fingerprint to deduce the schema id and resolve the schema from the the Schema Registry using the configured adapter. Event generation # In order to generate the events from Avro schema files using Maven, please use the following plugin: <build> <plugins> <plugin> <groupId> org.apache.avro </groupId> <artifactId> avro-maven-plugin </artifactId> <executions> <execution> <phase> generate-sources </phase> <goals> <goal> schema </goal> </goals> <configuration> <sourceDirectory> ${project.basedir}/src/main/resources/avro/ </sourceDirectory> <outputDirectory> ${project.build.directory}/generated-sources/avro/ </outputDirectory> <stringType> String </stringType> </configuration> </execution> </executions> </plugin> </plugins> </build> Serialization # To use Avro serialization in your application, Axon Serializer needs to be registered for the Eventbus. This requires implementing the org.axonframework.serialization.Serializer interface declared in axon-messaging . !!! note Axon Spring Autoconfiguration allows setting the serializers via application.yml . Currently, it only allows to select between jackson and xstream and is not used. The serializer receives the event instance of the generated class. It then: validates, if the instance fulfills the requirements (structure, required fields) defined in the schema. For this it needs to: determine schema URL and revision based on class meta data load the schema from the registry (and probably cache it) Creates a serializedType and serializedObject passed over to the eventbus / eventstore Deserialization # Since Axon Framework dispatches events to EventHandlers based on reflection and FQN, a system consuming events must also keep a java/kt class based on (= generated from) the schema. Since Avro takes care of checking compatibility between publisher and receiver schema, this does not have to be the same schema used to serialize the event. See Upcasting Section for more details.","title":"Implementation details"},{"location":"reference/index.html#encoding","text":"Apache Avro provides several encoding formats. The current extension uses Single Object Encoded format for binary data representation. Using this format, the encoded data is binary encoded and contains a special CRC-64-AVRO fingerprint of the object's schema. The extension is using this fingerprint to deduce the schema id and resolve the schema from the the Schema Registry using the configured adapter.","title":"Encoding"},{"location":"reference/index.html#event-generation","text":"In order to generate the events from Avro schema files using Maven, please use the following plugin: <build> <plugins> <plugin> <groupId> org.apache.avro </groupId> <artifactId> avro-maven-plugin </artifactId> <executions> <execution> <phase> generate-sources </phase> <goals> <goal> schema </goal> </goals> <configuration> <sourceDirectory> ${project.basedir}/src/main/resources/avro/ </sourceDirectory> <outputDirectory> ${project.build.directory}/generated-sources/avro/ </outputDirectory> <stringType> String </stringType> </configuration> </execution> </executions> </plugin> </plugins> </build>","title":"Event generation"},{"location":"reference/index.html#serialization","text":"To use Avro serialization in your application, Axon Serializer needs to be registered for the Eventbus. This requires implementing the org.axonframework.serialization.Serializer interface declared in axon-messaging . !!! note Axon Spring Autoconfiguration allows setting the serializers via application.yml . Currently, it only allows to select between jackson and xstream and is not used. The serializer receives the event instance of the generated class. It then: validates, if the instance fulfills the requirements (structure, required fields) defined in the schema. For this it needs to: determine schema URL and revision based on class meta data load the schema from the registry (and probably cache it) Creates a serializedType and serializedObject passed over to the eventbus / eventstore","title":"Serialization"},{"location":"reference/index.html#deserialization","text":"Since Axon Framework dispatches events to EventHandlers based on reflection and FQN, a system consuming events must also keep a java/kt class based on (= generated from) the schema. Since Avro takes care of checking compatibility between publisher and receiver schema, this does not have to be the same schema used to serialize the event. See Upcasting Section for more details.","title":"Deserialization"},{"location":"reference/axon-server-plugins.html","text":"Axon Server provides a dashboard for operation where you can search for events stored in the system. Since we use binary encoding for message serialization, the content is not human-readable. Luckily, Axon Server provides a plugin system based on OSGi, allowing to extend the functionality of the server. The extension provides a series of Axon Server plugins, to make the search of events inside the Axon Server dashboard usable with Avro serialized events. Axon Server Avro Serializer Plugin # The Axon Server Avro Serializer Plugin is providing the functionality of displaying the event payload in the Axon Server's dashboard. In doing so, it relies on one of the Axon Server Avro Registry Plugins to access the Schema Registry, required for deserialization. Axon Server Avro Registry Plugins # Since the deserialization itself is not coupled to a particular registry, we provide a series of Axon Server Plugins to connect with the Schema Registry used in your scenario. Currently the following plugins are available: Axon Server Apicurio Registry Plugin more to come... Installation of plugins # Download the Axon Server Avro Serializer Plugin and the corresponding Axon Server Avro Registry Plugin binaries Open Axon Server Dashboard and navigate to plugins Install both plugins Configure the Axon Server Avro Registry Plugin to connect to the registry Start both plugins","title":"Axon Server plugins"},{"location":"reference/axon-server-plugins.html#axon-server-avro-serializer-plugin","text":"The Axon Server Avro Serializer Plugin is providing the functionality of displaying the event payload in the Axon Server's dashboard. In doing so, it relies on one of the Axon Server Avro Registry Plugins to access the Schema Registry, required for deserialization.","title":"Axon Server Avro Serializer Plugin"},{"location":"reference/axon-server-plugins.html#axon-server-avro-registry-plugins","text":"Since the deserialization itself is not coupled to a particular registry, we provide a series of Axon Server Plugins to connect with the Schema Registry used in your scenario. Currently the following plugins are available: Axon Server Apicurio Registry Plugin more to come...","title":"Axon Server Avro Registry Plugins"},{"location":"reference/axon-server-plugins.html#installation-of-plugins","text":"Download the Axon Server Avro Serializer Plugin and the corresponding Axon Server Avro Registry Plugin binaries Open Axon Server Dashboard and navigate to plugins Install both plugins Configure the Axon Server Avro Registry Plugin to connect to the registry Start both plugins","title":"Installation of plugins"},{"location":"reference/registry-adapters.html","text":"The Avro Registry Adapter project provides several registry adapter, which need to be configured for use with the Avro Serializer. Apicurio Registry Adapter # The Apicurio registry adapter requires a connection configuration including the host and the port of the registry. @Bean fun apicurioRegistryClient ( @Value ( \"\\ ${ apicurio . registry . host } \" ) host : String , @Value ( \"\\ ${ apicurio . registry . port } \" ) port : Int ): RegistryClient = AvroAdapterApicurioRest . registryRestClient ( host , port ) @Bean fun avroSchemaRegistry ( apicurioRegistryClient : RegistryClient ) = ApicurioAvroSchemaRegistry ( client = GroupAwareRegistryClient ( apicurioRegistryClient , AvroAdapterDefault . schemaIdSupplier , AvroAdapterDefault . schemaRevisionResolver ), schemaIdSupplier = AvroAdapterDefault . schemaIdSupplier , schemaRevisionResolver = AvroAdapterDefault . schemaRevisionResolver )","title":"Registry adapters"},{"location":"reference/registry-adapters.html#apicurio-registry-adapter","text":"The Apicurio registry adapter requires a connection configuration including the host and the port of the registry. @Bean fun apicurioRegistryClient ( @Value ( \"\\ ${ apicurio . registry . host } \" ) host : String , @Value ( \"\\ ${ apicurio . registry . port } \" ) port : Int ): RegistryClient = AvroAdapterApicurioRest . registryRestClient ( host , port ) @Bean fun avroSchemaRegistry ( apicurioRegistryClient : RegistryClient ) = ApicurioAvroSchemaRegistry ( client = GroupAwareRegistryClient ( apicurioRegistryClient , AvroAdapterDefault . schemaIdSupplier , AvroAdapterDefault . schemaRevisionResolver ), schemaIdSupplier = AvroAdapterDefault . schemaIdSupplier , schemaRevisionResolver = AvroAdapterDefault . schemaRevisionResolver )","title":"Apicurio Registry Adapter"}]}